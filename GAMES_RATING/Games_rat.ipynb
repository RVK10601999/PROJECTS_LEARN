{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Games_rat.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR_fhsjiOx1B"
      },
      "source": [
        "# Importing necesssary libraries...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HouDB7piOwJR",
        "outputId": "e23ddb42-7768-492e-9fa7-dffa096a5c71"
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from jupyterthemes import jtplot\n",
        "\n",
        "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws2zFkFTOwJZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI_-2wwjO6Qo"
      },
      "source": [
        "# Importing dataset..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoHypKZkOwJa"
      },
      "source": [
        "df = pd.read_csv(\"C:\\\\Users\\\\rvkmc\\\\Downloads\\\\Video_games_esrb_rating.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOqmId9yOwJb",
        "outputId": "17fb1218-458f-4303-a118-94b3108caaeb"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>console</th>\n",
              "      <th>alcohol_reference</th>\n",
              "      <th>animated_blood</th>\n",
              "      <th>blood</th>\n",
              "      <th>blood_and_gore</th>\n",
              "      <th>cartoon_violence</th>\n",
              "      <th>crude_humor</th>\n",
              "      <th>drug_reference</th>\n",
              "      <th>fantasy_violence</th>\n",
              "      <th>...</th>\n",
              "      <th>sexual_content</th>\n",
              "      <th>sexual_themes</th>\n",
              "      <th>simulated_gambling</th>\n",
              "      <th>strong_janguage</th>\n",
              "      <th>strong_sexual_content</th>\n",
              "      <th>suggestive_themes</th>\n",
              "      <th>use_of_alcohol</th>\n",
              "      <th>use_of_drugs_and_alcohol</th>\n",
              "      <th>violence</th>\n",
              "      <th>esrb_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Monster Jam Steel Titans 2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subnautica: Below Zero</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ET</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NIER REPLICANT VER.1.22474487139â€¦</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jamestown+</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ET</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Neptunia Virtual Stars</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1890</th>\n",
              "      <td>SENRAN KAGURA Peach Beach Splash</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1891</th>\n",
              "      <td>Sneaky Bears</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1892</th>\n",
              "      <td>SPARC</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1893</th>\n",
              "      <td>Still Time</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1894</th>\n",
              "      <td>Surf World Series</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1895 rows Ã— 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  title  console  alcohol_reference  \\\n",
              "0            Monster Jam Steel Titans 2        1                  0   \n",
              "1                Subnautica: Below Zero        1                  0   \n",
              "2     NIER REPLICANT VER.1.22474487139â€¦        1                  0   \n",
              "3                            Jamestown+        0                  0   \n",
              "4                Neptunia Virtual Stars        0                  0   \n",
              "...                                 ...      ...                ...   \n",
              "1890   SENRAN KAGURA Peach Beach Splash        0                  0   \n",
              "1891                       Sneaky Bears        0                  0   \n",
              "1892                              SPARC        0                  0   \n",
              "1893                         Still Time        0                  0   \n",
              "1894                  Surf World Series        1                  0   \n",
              "\n",
              "      animated_blood  blood  blood_and_gore  cartoon_violence  crude_humor  \\\n",
              "0                  0      0               0                 0            0   \n",
              "1                  1      0               0                 0            0   \n",
              "2                  0      1               0                 0            0   \n",
              "3                  0      0               0                 0            0   \n",
              "4                  0      0               0                 0            0   \n",
              "...              ...    ...             ...               ...          ...   \n",
              "1890               0      0               0                 0            0   \n",
              "1891               0      0               0                 0            0   \n",
              "1892               0      0               0                 0            0   \n",
              "1893               0      1               0                 0            0   \n",
              "1894               0      0               0                 0            0   \n",
              "\n",
              "      drug_reference  fantasy_violence  ...  sexual_content  sexual_themes  \\\n",
              "0                  0                 0  ...               0              0   \n",
              "1                  0                 0  ...               0              0   \n",
              "2                  0                 0  ...               0              0   \n",
              "3                  0                 1  ...               0              0   \n",
              "4                  0                 1  ...               0              0   \n",
              "...              ...               ...  ...             ...            ...   \n",
              "1890               0                 1  ...               1              1   \n",
              "1891               0                 1  ...               0              0   \n",
              "1892               0                 0  ...               0              0   \n",
              "1893               0                 0  ...               0              0   \n",
              "1894               0                 0  ...               0              0   \n",
              "\n",
              "      simulated_gambling  strong_janguage  strong_sexual_content  \\\n",
              "0                      0                0                      0   \n",
              "1                      0                0                      0   \n",
              "2                      0                1                      0   \n",
              "3                      0                0                      0   \n",
              "4                      0                0                      0   \n",
              "...                  ...              ...                    ...   \n",
              "1890                   0                1                      0   \n",
              "1891                   0                0                      0   \n",
              "1892                   0                0                      0   \n",
              "1893                   0                0                      0   \n",
              "1894                   0                0                      0   \n",
              "\n",
              "      suggestive_themes  use_of_alcohol  use_of_drugs_and_alcohol  violence  \\\n",
              "0                     0               0                         0         0   \n",
              "1                     0               0                         0         0   \n",
              "2                     1               0                         0         0   \n",
              "3                     0               0                         0         0   \n",
              "4                     1               0                         0         0   \n",
              "...                 ...             ...                       ...       ...   \n",
              "1890                  0               0                         0         0   \n",
              "1891                  0               0                         0         0   \n",
              "1892                  0               0                         0         0   \n",
              "1893                  0               0                         0         0   \n",
              "1894                  0               0                         0         0   \n",
              "\n",
              "      esrb_rating  \n",
              "0               E  \n",
              "1              ET  \n",
              "2               M  \n",
              "3              ET  \n",
              "4               T  \n",
              "...           ...  \n",
              "1890            M  \n",
              "1891            T  \n",
              "1892            E  \n",
              "1893            T  \n",
              "1894            E  \n",
              "\n",
              "[1895 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zknBdm8uPAfx"
      },
      "source": [
        "# Checking for missing values..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naptJHa8OwJb",
        "outputId": "243bc5f9-3fef-483a-e74c-88dbd78d225b"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title                       0\n",
              "console                     0\n",
              "alcohol_reference           0\n",
              "animated_blood              0\n",
              "blood                       0\n",
              "blood_and_gore              0\n",
              "cartoon_violence            0\n",
              "crude_humor                 0\n",
              "drug_reference              0\n",
              "fantasy_violence            0\n",
              "intense_violence            0\n",
              "language                    0\n",
              "lyrics                      0\n",
              "mature_humor                0\n",
              "mild_blood                  0\n",
              "mild_cartoon_violence       0\n",
              "mild_fantasy_violence       0\n",
              "mild_language               0\n",
              "mild_lyrics                 0\n",
              "mild_suggestive_themes      0\n",
              "mild_violence               0\n",
              "no_descriptors              0\n",
              "nudity                      0\n",
              "partial_nudity              0\n",
              "sexual_content              0\n",
              "sexual_themes               0\n",
              "simulated_gambling          0\n",
              "strong_janguage             0\n",
              "strong_sexual_content       0\n",
              "suggestive_themes           0\n",
              "use_of_alcohol              0\n",
              "use_of_drugs_and_alcohol    0\n",
              "violence                    0\n",
              "esrb_rating                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoqFVHHiOwJc"
      },
      "source": [
        "df = df.drop(columns=['title'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBXizJsJOwJc",
        "outputId": "5463295c-d273-44df-e327-a3c3f9fa0237"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['console', 'alcohol_reference', 'animated_blood', 'blood',\n",
              "       'blood_and_gore', 'cartoon_violence', 'crude_humor', 'drug_reference',\n",
              "       'fantasy_violence', 'intense_violence', 'language', 'lyrics',\n",
              "       'mature_humor', 'mild_blood', 'mild_cartoon_violence',\n",
              "       'mild_fantasy_violence', 'mild_language', 'mild_lyrics',\n",
              "       'mild_suggestive_themes', 'mild_violence', 'no_descriptors', 'nudity',\n",
              "       'partial_nudity', 'sexual_content', 'sexual_themes',\n",
              "       'simulated_gambling', 'strong_janguage', 'strong_sexual_content',\n",
              "       'suggestive_themes', 'use_of_alcohol', 'use_of_drugs_and_alcohol',\n",
              "       'violence', 'esrb_rating'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtcSaPvyPXiR"
      },
      "source": [
        "# Checking for commonalities....."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa_1ieqlOwJd",
        "outputId": "937a8b73-c14b-41c8-dcd7-1b3821a98e4a"
      },
      "source": [
        "df[['alcohol_reference','drug_reference']].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alcohol_reference  drug_reference\n",
              "0                  0                 1738\n",
              "1                  0                   91\n",
              "0                  1                   62\n",
              "1                  1                    4\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARvJoQqFOwJe",
        "outputId": "b08f8acf-3ad6-42c5-c13d-d3fb12fa8288"
      },
      "source": [
        "df[['animated_blood','blood','blood_and_gore']].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "animated_blood  blood  blood_and_gore\n",
              "0               0      0                 1205\n",
              "                1      0                  432\n",
              "                0      1                  239\n",
              "1               0      0                   19\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI-GLlk2OwJe",
        "outputId": "f28371da-6be7-4f33-9a51-9d994deb045f"
      },
      "source": [
        "df[['blood','blood_and_gore']].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "blood  blood_and_gore\n",
              "0      0                 1224\n",
              "1      0                  432\n",
              "0      1                  239\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfWTya5TOwJf",
        "outputId": "83ed0904-4665-420e-dd2f-aa21f4da38e5"
      },
      "source": [
        "df[['cartoon_violence','fantasy_violence']].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cartoon_violence  fantasy_violence\n",
              "0                 0                   1440\n",
              "                  1                    418\n",
              "1                 0                     37\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8xb7AfsOwJg",
        "outputId": "863f4b7d-2c65-46b0-b767-31cf14feedc3"
      },
      "source": [
        "df[['crude_humor','mature_humor']].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "crude_humor  mature_humor\n",
              "0            0               1772\n",
              "1            0                101\n",
              "0            1                 20\n",
              "1            1                  2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkGE0kZZOwJh",
        "outputId": "1ae9f596-6e10-435f-c178-ade2471b1004"
      },
      "source": [
        "df[['partial_nudity','nudity']].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "partial_nudity  nudity\n",
              "0               0         1842\n",
              "                1           28\n",
              "1               0           25\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoXVGDMSOwJh",
        "outputId": "202f7db4-aea2-4dce-c216-c954f6a55636"
      },
      "source": [
        "df[['sexual_content','strong_sexual_content','sexual_themes']].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sexual_content  strong_sexual_content  sexual_themes\n",
              "0               0                      0                1666\n",
              "                                       1                  99\n",
              "                1                      0                  62\n",
              "1               0                      0                  55\n",
              "                                       1                   7\n",
              "                1                      0                   3\n",
              "0               1                      1                   3\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlvx78ztOwJh",
        "outputId": "12d50f56-8383-4aaa-efce-d17cb45ed984"
      },
      "source": [
        "df[['alcohol_reference','use_of_alcohol']].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alcohol_reference  use_of_alcohol\n",
              "0                  0                 1780\n",
              "1                  0                   85\n",
              "0                  1                   20\n",
              "1                  1                   10\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA9yI-rIOwJi",
        "outputId": "fa95d0b2-2962-41c0-e226-18f5e97f75c3"
      },
      "source": [
        "df[['drug_reference','use_of_drugs_and_alcohol']].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "drug_reference  use_of_drugs_and_alcohol\n",
              "0               0                           1799\n",
              "1               0                             66\n",
              "0               1                             30\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "zrhXAXCOOwJi",
        "outputId": "6e2f07b3-7c33-487d-9d19-d756dbe4c629"
      },
      "source": [
        "df[['cartoon_violence','fantasy_violence','violence']].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cartoon_violence  fantasy_violence  violence\n",
              "0                 0                 0           1329\n",
              "                  1                 0            408\n",
              "                  0                 1            111\n",
              "1                 0                 0             37\n",
              "0                 1                 1             10\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uspv9dtAPgN5"
      },
      "source": [
        "# train-test split..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFt3LdrwOwJi"
      },
      "source": [
        "X = df.drop(columns=['esrb_rating'])\n",
        "y = df['esrb_rating']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_s8pBTXOwJj",
        "outputId": "f5d2a9d2-a893-4d2b-b362-a0dd17fef838"
      },
      "source": [
        "y.value_counts()/y.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T     0.363588\n",
              "E     0.219525\n",
              "ET    0.212665\n",
              "M     0.204222\n",
              "Name: esrb_rating, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSS008o4OwJj"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbO92ns4OwJj"
      },
      "source": [
        "xtr,xts,ytr,yts = train_test_split(X,y,train_size=.7,random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3HCd9bGOwJj"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vGVMStvPkXc"
      },
      "source": [
        "# Using two ensemble techniques for best possible classification..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prnoRZ8LOwJk"
      },
      "source": [
        "prmgrd = {\n",
        "    'n_estimators':[150,200,250,300],\n",
        "    'criterion':['gini','entropy'],\n",
        "    'random_state':[123],\n",
        "    'max_features':['auto','log2','sqrt'],\n",
        "    'n_jobs':[-1]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA1aPEPkOwJk"
      },
      "source": [
        "prmgrd1 = {\n",
        "    'n_estimators':[300,350,400],\n",
        "    'booster':['gbtree','gblinear','dart'],\n",
        "    'n_jobs':[-1],\n",
        "    'random_state':[123]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oibywG2OwJk"
      },
      "source": [
        "gcvrf = GridSearchCV(estimator=RandomForestClassifier(),param_grid=prmgrd,n_jobs=-1)\n",
        "gcvxg = GridSearchCV(estimator=XGBClassifier(),param_grid=prmgrd1,n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VxX7Sq98OwJl",
        "outputId": "23b62c90-e0ca-4631-e7c6-120639bc69b1"
      },
      "source": [
        "gcvrf.fit(xtr,ytr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_features': ['auto', 'log2', 'sqrt'],\n",
              "                         'n_estimators': [150, 200, 250, 300], 'n_jobs': [-1],\n",
              "                         'random_state': [123]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMtJHrM6OwJl",
        "outputId": "714c7acc-2f6f-4ca6-a01e-11ec0b7b7385"
      },
      "source": [
        "gcvrf.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini',\n",
              " 'max_features': 'auto',\n",
              " 'n_estimators': 200,\n",
              " 'n_jobs': -1,\n",
              " 'random_state': 123}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUz4srdIOwJl",
        "outputId": "970def77-f89b-4e17-dfd2-fb85e510efa2"
      },
      "source": [
        "gcvxg.fit(xtr,ytr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[20:44:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                     colsample_bylevel=None,\n",
              "                                     colsample_bynode=None,\n",
              "                                     colsample_bytree=None, gamma=None,\n",
              "                                     gpu_id=None, importance_type='gain',\n",
              "                                     interaction_constraints=None,\n",
              "                                     learning_rate=None, max_delta_step=None,\n",
              "                                     max_depth=None, min_child_weight=None,\n",
              "                                     missing=nan, monotone_constraints=None,\n",
              "                                     n_estimators=100, n_jobs=None,\n",
              "                                     num_parallel_tree=None, random_state=None,\n",
              "                                     reg_alpha=None, reg_lambda=None,\n",
              "                                     scale_pos_weight=None, subsample=None,\n",
              "                                     tree_method=None, validate_parameters=None,\n",
              "                                     verbosity=None),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'booster': ['gbtree', 'gblinear', 'dart'],\n",
              "                         'n_estimators': [150, 200, 250, 300], 'n_jobs': [-1],\n",
              "                         'random_state': [123]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fRqffVqOwJm",
        "outputId": "5d96739f-1fe4-40f7-d1f4-dd9f6a095fbe"
      },
      "source": [
        "gcvxg.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'booster': 'dart', 'n_estimators': 300, 'n_jobs': -1, 'random_state': 123}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBTG0WiTOwJm",
        "outputId": "dbe1e790-93ac-4539-bb34-a62c83010939"
      },
      "source": [
        "gcvrf.score(xtr,ytr),gcvrf.score(xts,yts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9306184012066365, 0.8506151142355008)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLKDWHPIOwJm",
        "outputId": "424cf05e-3191-4881-8192-9952857d2ee5"
      },
      "source": [
        "gcvxg.score(xtr,ytr),gcvxg.score(xts,yts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9306184012066365, 0.8611599297012302)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krqcnFChOwJm"
      },
      "source": [
        "bstrf = RandomForestClassifier(criterion='gini',\n",
        " max_features='auto',\n",
        " n_estimators=200,\n",
        " n_jobs= -1,\n",
        " random_state= 123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFrDXhcGOwJm"
      },
      "source": [
        "bstxg = XGBClassifier(booster='dart', n_estimators=250, n_jobs= -1, random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHifmDBIOwJm"
      },
      "source": [
        "skf = StratifiedKFold(n_splits=50,shuffle=True,random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4FySdKjOwJn",
        "outputId": "6916f68f-2805-46cf-9379-efe44c487ce4"
      },
      "source": [
        "for tri,tsi in skf.split(X=X,y=y):\n",
        "    xtrf,xtsf = X.iloc[tri],X.iloc[tsi]\n",
        "    ytrf,ytsf = y.iloc[tri],y.iloc[tsi]\n",
        "    bstrf.fit(xtrf,ytrf)\n",
        "    bstxg.fit(xtrf,ytrf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:11:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:11:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:11:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:12:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:12:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:12:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:12:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:12:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:12:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:12:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:12:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:13:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:13:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:13:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:13:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:13:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:13:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:13:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:13:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:13:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:13:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:13:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:14:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:14:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:14:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:14:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:14:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:14:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:15:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:15:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:15:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:15:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:15:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:15:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:15:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:16:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:16:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:16:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:16:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=123)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rvkmc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[21:16:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
              "              importance_type='gain', interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=-1, num_parallel_tree=1,\n",
              "              objective='multi:softprob', random_state=123, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
              "              tree_method='exact', validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4oYnCqTPyN6"
      },
      "source": [
        "# Note that both models have the same scores, which means models are trained to the maximum...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZwHsSpAOwJo",
        "outputId": "9025190a-806d-418a-8091-a6af03871de8"
      },
      "source": [
        "bstrf.score(xtr,ytr),bstrf.score(xts,yts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9253393665158371, 0.9209138840070299)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1AmNQTJOwJo",
        "outputId": "a6bc77df-f54f-4ec5-d186-a2e2847b6d51"
      },
      "source": [
        "bstxg.score(xtr,ytr),bstxg.score(xts,yts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9253393665158371, 0.9209138840070299)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JanFjmWOwJp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}